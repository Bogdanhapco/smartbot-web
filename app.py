import os
import re
import urllib.request
import json
import math
import random
from PIL import Image, ImageDraw
import streamlit as st
import requests
import io

# --- Groq API Key (your key is already here) ---
GROQ_API_KEY = "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"

# --- Groq Endpoints ---
GROQ_CHAT_URL = "https://api.groq.com/openai/v1/chat/completions"
GROQ_IMAGE_URL = "https://api.groq.com/openai/v1/images/generations"

# --- KNOWLEDGE ENGINE ---
class KnowledgeEngine:
    def __init__(self):
        self.cache = {}
    
    def search(self, query):
        raw_query = query.lower()
        if raw_query in self.cache:
            return self.cache[raw_query]
        
        try:
            result = self._search_wikipedia(query)
            self.cache[raw_query] = result
            return result
        except Exception as e:
            return None  # Return None on error so we can show custom message
    
    def _search_wikipedia(self, query):
        subject = query.lower()
        for word in ["what is the", "what is", "who is", "tell me about", "explain"]:
            subject = subject.replace(word, "")
        subject = subject.replace("?", "").strip()
        
        search_url = f"https://en.wikipedia.org/w/api.php?action=query&list=search&srsearch={subject.replace(' ', '%20')}&format=json"
        req = urllib.request.Request(search_url, headers={'User-Agent': 'Mozilla/5.0'})
        
        with urllib.request.urlopen(req, timeout=5) as r:
            s_data = json.loads(r.read().decode())
            results = s_data.get('query', {}).get('search', [])
            if not results:
                return None
            best_title = results[0]['title']
        
        content_url = f"https://en.wikipedia.org/w/api.php?action=query&prop=extracts&explaintext&titles={best_title.replace(' ', '_')}&format=json&redirects=1"
        req2 = urllib.request.Request(content_url, headers={'User-Agent': 'Mozilla/5.0'})
        
        with urllib.request.urlopen(req2, timeout=5) as r2:
            data = json.loads(r2.read().decode())
            page = list(data['query']['pages'].values())[0]
            full_text = page.get('extract', "")
            sentences = re.split(r'(?<=[.!?]) +', full_text)
            return " ".join(sentences[:4])

# --- Keep PromptParser & Renderer (your old drawing system) ---
# (Your full classes go here - I kept them unchanged, paste your original code if needed)

# --- Chat with Groq LLM for natural conversation ---
def chat_with_groq(message):
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "llama3-70b-8192",  # Fast & natural
        "messages": [{"role": "user", "content": message}],
        "temperature": 0.7,
        "max_tokens": 500
    }
    try:
        response = requests.post(GROQ_CHAT_URL, headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        content = response.json()['choices'][0]['message']['content']
        
        # Special reply for "who made you" questions
        if any(word in message.lower() for word in ["who made you", "who created you", "who built you", "who developed you"]):
            return "I was created by BotDevelopmentAI ðŸ˜Š"
        
        return content
    except Exception as e:
        return None  # Return None on error â†’ show custom message

# --- Generate image with Groq Flux.1-schnell ---
def generate_image_with_groq(prompt):
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "flux-schnell",
        "prompt": prompt,
        "size": "1024x1024"
    }
    try:
        response = requests.post(GROQ_IMAGE_URL, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        image_url = response.json()['data'][0]['url']
        img_response = requests.get(image_url)
        return Image.open(io.BytesIO(img_response.content))
    except Exception as e:
        return None

# --- Streamlit App ---
st.set_page_config(page_title="SmartBot Advanced Web Edition", layout="wide")

st.title("ðŸ¤– SmartBot Advanced v27 - Web Edition")
st.markdown("""
**Capabilities:**
â€¢ Natural conversation (ask anything!)
â€¢ Knowledge from Wikipedia with reasoning
â€¢ Procedural drawing ("draw a red car")
â€¢ Real AI image generation with SmartBot Ludy Model ("generate image of...")
""")

# Chat history
if 'messages' not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "image" in message:
            st.image(message["image"])

# Input
prompt = st.chat_input("Talk to me...")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.spinner("Thinking..."):
        query_lower = prompt.lower()

        # Image generation
        if any(word in query_lower for word in ["generate image", "flux image", "ai image", "make image"]):
            desc = prompt.lower().replace("generate image", "").replace("flux image", "").replace("ai image", "").replace("make image", "").strip()
            with st.spinner("Generating Image With SmartBot Ludy..."):
                img = generate_image_with_groq(desc)
                if img:
                    response = f"Here is your image: **{desc}**"
                    st.session_state.messages.append({"role": "assistant", "content": response, "image": img})
                    with st.chat_message("assistant"):
                        st.markdown(response)
                        st.image(img)
                        st.download_button("Download Image", img.tobytes(), "smartbot_image.png", "image/png")
                else:
                    response = "Error: Could not generate image. Check API key or quota."
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    with st.chat_message("assistant"):
                        st.markdown(response)

        # Old procedural drawing (keep your original code here)
        elif any(word in query_lower for word in ["draw", "create drawing", "render scene"]):
            # Paste your full drawing logic here (PromptParser + Renderer)
            # Example placeholder:
            response = "Old drawing would appear here (add your full renderer code)"
            st.session_state.messages.append({"role": "assistant", "content": response})
            with st.chat_message("assistant"):
                st.markdown(response)

        # Normal chat / everything else
        else:
            answer = chat_with_groq(prompt)
            if answer:
                st.session_state.messages.append({"role": "assistant", "content": answer})
                with st.chat_message("assistant"):
                    st.markdown(answer)
            else:
                response = "Error: Answer not found."
                st.session_state.messages.append({"role": "assistant", "content": response})
                with st.chat_message("assistant"):
                    st.markdown(response)


